nohup: ignoring input
/home/xiao/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/xiao/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
  warn(f"Failed to load image Python extension: {e}")
/home/xiao/code/CS5242/CS5242/main_drop_flip.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  one_gt=torch.tensor(one_gt,dtype=torch.float32)
[epoch:0] loss 0.7269630233446757 acc 0.5138888888888888
[epoch:0] test loss 0.6993805425507682 test acc 0.39955357142857145
[epoch:1] loss 0.7105230159229703 acc 0.5303819444444444
[epoch:1] test loss 0.6967311416353498 test acc 0.40625
[epoch:2] loss 0.6893806391292148 acc 0.6024305555555556
[epoch:2] test loss 0.69729426077434 test acc 0.4029017857142857
[epoch:3] loss 0.6949716607729594 acc 0.5390625
[epoch:3] test loss 0.698819671358381 test acc 0.40401785714285715
[epoch:4] loss 0.687188082271152 acc 0.6015625
[epoch:4] test loss 0.6996769819940839 test acc 0.40513392857142855
[epoch:5] loss 0.6800357964303758 acc 0.5503472222222222
[epoch:5] test loss 0.7008716889790126 test acc 0.4029017857142857
[epoch:6] loss 0.6852212018436856 acc 0.6015625
[epoch:6] test loss 0.7023519788469587 test acc 0.40401785714285715
[epoch:7] loss 0.694099227587382 acc 0.5564236111111112
[epoch:7] test loss 0.703298739024571 test acc 0.40401785714285715
[epoch:8] loss 0.6830054322878519 acc 0.6032986111111112
[epoch:8] test loss 0.7049964070320129 test acc 0.39732142857142855
[epoch:9] loss 0.6915457712279426 acc 0.5590277777777778
[epoch:9] test loss 0.7042602556092399 test acc 0.40625
[epoch:10] loss 0.6820081273714701 acc 0.6015625
[epoch:10] test loss 0.7052309513092041 test acc 0.40848214285714285
Epoch 00012: reducing learning rate of group 0 to 8.0000e-05.
[epoch:11] loss 0.6846251090367635 acc 0.5677083333333334
[epoch:11] test loss 0.7071896876607623 test acc 0.40066964285714285
[epoch:12] loss 0.6804256704118516 acc 0.6032986111111112
[epoch:12] test loss 0.7078605209078107 test acc 0.40401785714285715
[epoch:13] loss 0.671133385764228 acc 0.5824652777777778
[epoch:13] test loss 0.7084405762808663 test acc 0.40513392857142855
[epoch:14] loss 0.6790663997332255 acc 0.6041666666666666
[epoch:14] test loss 0.7109577996390206 test acc 0.3950892857142857
[epoch:15] loss 0.6801624364323087 acc 0.5607638888888888
[epoch:15] test loss 0.7099129131862095 test acc 0.40401785714285715
[epoch:16] loss 0.6782466040717231 acc 0.6041666666666666
[epoch:16] test loss 0.7108597159385681 test acc 0.3984375
[epoch:17] loss 0.6798768705791898 acc 0.5746527777777778
[epoch:17] test loss 0.7111886739730835 test acc 0.3950892857142857
[epoch:18] loss 0.6782268948025174 acc 0.6015625
[epoch:18] test loss 0.7105476771082196 test acc 0.4029017857142857
Epoch 00020: reducing learning rate of group 0 to 6.4000e-05.
[epoch:19] loss 0.6751861439810859 acc 0.5763888888888888
[epoch:19] test loss 0.7117983783994403 test acc 0.40513392857142855
[epoch:20] loss 0.6760915385352241 acc 0.6041666666666666
[epoch:20] test loss 0.7128873893192836 test acc 0.40513392857142855
[epoch:21] loss 0.6771712170706855 acc 0.5677083333333334
[epoch:21] test loss 0.71278658083507 test acc 0.40848214285714285
[epoch:22] loss 0.6747283207045661 acc 0.6050347222222222
[epoch:22] test loss 0.7139323779514858 test acc 0.40736607142857145
[epoch:23] loss 0.6787400841712952 acc 0.5711805555555556
[epoch:23] test loss 0.713839590549469 test acc 0.40736607142857145
[epoch:24] loss 0.6745832628673978 acc 0.6006944444444444
[epoch:24] test loss 0.7138454743794033 test acc 0.40848214285714285
Epoch 00026: reducing learning rate of group 0 to 5.1200e-05.
[epoch:25] loss 0.674671126736535 acc 0.5633680555555556
[epoch:25] test loss 0.7141219973564148 test acc 0.40401785714285715
[epoch:26] loss 0.6735667983690897 acc 0.6050347222222222
[epoch:26] test loss 0.7141905001231602 test acc 0.40736607142857145
[epoch:27] loss 0.6666973034540812 acc 0.5815972222222222
[epoch:27] test loss 0.7157134413719177 test acc 0.40401785714285715
[epoch:28] loss 0.6725612746344672 acc 0.6024305555555556
[epoch:28] test loss 0.718170131955828 test acc 0.4017857142857143
[epoch:29] loss 0.6741556061638726 acc 0.5928819444444444
[epoch:29] test loss 0.716831488268716 test acc 0.40513392857142855
[epoch:30] loss 0.6711825860871209 acc 0.6041666666666666
[epoch:30] test loss 0.717793447630746 test acc 0.40401785714285715
[epoch:31] loss 0.6748120188713074 acc 0.5868055555555556
[epoch:31] test loss 0.718385670866285 test acc 0.4029017857142857
[epoch:32] loss 0.6694482498698764 acc 0.6067708333333334
[epoch:32] test loss 0.7179204651287624 test acc 0.40513392857142855
Epoch 00034: reducing learning rate of group 0 to 4.0960e-05.
[epoch:33] loss 0.6711512737803988 acc 0.5711805555555556
[epoch:33] test loss 0.7178571479661124 test acc 0.4029017857142857
[epoch:34] loss 0.6683797306484647 acc 0.6067708333333334
[epoch:34] test loss 0.7178533502987453 test acc 0.4029017857142857
[epoch:35] loss 0.6661680539449056 acc 0.5789930555555556
[epoch:35] test loss 0.7180372306278774 test acc 0.4017857142857143
[epoch:36] loss 0.6675441861152649 acc 0.6041666666666666
[epoch:36] test loss 0.7182908228465489 test acc 0.40513392857142855
[epoch:37] loss 0.6722998221715292 acc 0.5755208333333334
[epoch:37] test loss 0.7188673445156643 test acc 0.40736607142857145
[epoch:38] loss 0.666309826903873 acc 0.6024305555555556
[epoch:38] test loss 0.7211645245552063 test acc 0.40401785714285715
[epoch:39] loss 0.6717368165651957 acc 0.5798611111111112
[epoch:39] test loss 0.7221133879252842 test acc 0.4029017857142857
Highest Test ACC : 0.40848214285714285
