nohup: ignoring input
/home/xiao/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/xiao/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
  warn(f"Failed to load image Python extension: {e}")
/home/xiao/code/CS5242/CS5242/main.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  one_gt=torch.tensor(one_gt,dtype=torch.float32)
[epoch:0] loss 0.9306716322898865 acc 0.5277777777777778
[epoch:0] test loss 0.7038453561919076 test acc 0.40513392857142855
[epoch:1] loss 0.8210753136210971 acc 0.5442708333333334
[epoch:1] test loss 0.7041013496262687 test acc 0.40066964285714285
[epoch:2] loss 0.8144756091965569 acc 0.515625
[epoch:2] test loss 0.7031336767332894 test acc 0.40736607142857145
[epoch:3] loss 0.7496890226999918 acc 0.5295138888888888
[epoch:3] test loss 0.704064062663487 test acc 0.39732142857142855
[epoch:4] loss 0.7212254934840732 acc 0.5494791666666666
[epoch:4] test loss 0.7033825772149223 test acc 0.40736607142857145
[epoch:5] loss 0.7159916957219442 acc 0.5286458333333334
[epoch:5] test loss 0.704227260180882 test acc 0.4017857142857143
[epoch:6] loss 0.7301726539929708 acc 0.5251736111111112
[epoch:6] test loss 0.7035689864839826 test acc 0.4107142857142857
[epoch:7] loss 0.703603208065033 acc 0.5434027777777778
[epoch:7] test loss 0.7046282376561847 test acc 0.4029017857142857
[epoch:8] loss 0.6852475338511996 acc 0.5789930555555556
[epoch:8] test loss 0.7043573004858834 test acc 0.40848214285714285
[epoch:9] loss 0.696698698732588 acc 0.5659722222222222
[epoch:9] test loss 0.7052382060459682 test acc 0.40401785714285715
[epoch:10] loss 0.692598839600881 acc 0.5598958333333334
[epoch:10] test loss 0.7055877276829311 test acc 0.40401785714285715
[epoch:11] loss 0.6926479803191291 acc 0.5633680555555556
[epoch:11] test loss 0.7058080605098179 test acc 0.40513392857142855
[epoch:12] loss 0.6889241072866652 acc 0.5685763888888888
[epoch:12] test loss 0.7063117112432208 test acc 0.40401785714285715
[epoch:13] loss 0.6785214145978292 acc 0.5842013888888888
[epoch:13] test loss 0.7069781167166573 test acc 0.4017857142857143
[epoch:14] loss 0.686280283663008 acc 0.5876736111111112
[epoch:14] test loss 0.7070829272270203 test acc 0.40401785714285715
[epoch:15] loss 0.6872083213594224 acc 0.5894097222222222
[epoch:15] test loss 0.7070660165378025 test acc 0.40736607142857145
[epoch:16] loss 0.684830281469557 acc 0.5789930555555556
[epoch:16] test loss 0.7077263849122184 test acc 0.40513392857142855
[epoch:17] loss 0.6910259193844266 acc 0.5755208333333334
[epoch:17] test loss 0.707832361970629 test acc 0.40736607142857145
[epoch:18] loss 0.6849400732252333 acc 0.5737847222222222
[epoch:18] test loss 0.7083768418857029 test acc 0.40625
Epoch 00020: reducing learning rate of group 0 to 8.0000e-05.
[epoch:19] loss 0.6847247083981832 acc 0.5807291666666666
[epoch:19] test loss 0.7090898837362017 test acc 0.40401785714285715
[epoch:20] loss 0.6829793784353468 acc 0.578125
[epoch:20] test loss 0.7092246157782418 test acc 0.40513392857142855
[epoch:21] loss 0.6806779238912795 acc 0.5694444444444444
[epoch:21] test loss 0.7092026557241168 test acc 0.40736607142857145
[epoch:22] loss 0.6809883183903165 acc 0.5868055555555556
[epoch:22] test loss 0.7100287590708051 test acc 0.40401785714285715
[epoch:23] loss 0.6826123860147264 acc 0.5815972222222222
[epoch:23] test loss 0.7103625961712429 test acc 0.40401785714285715
[epoch:24] loss 0.6866785883903503 acc 0.5920138888888888
[epoch:24] test loss 0.7103430884225028 test acc 0.40625
Epoch 00026: reducing learning rate of group 0 to 6.4000e-05.
[epoch:25] loss 0.6826624141799079 acc 0.5833333333333334
[epoch:25] test loss 0.7102993300982884 test acc 0.40848214285714285
[epoch:26] loss 0.6780180268817477 acc 0.5954861111111112
[epoch:26] test loss 0.7111847911562238 test acc 0.40401785714285715
[epoch:27] loss 0.6850179698732164 acc 0.5833333333333334
[epoch:27] test loss 0.7114191736493792 test acc 0.40401785714285715
[epoch:28] loss 0.682130946053399 acc 0.5789930555555556
[epoch:28] test loss 0.7108994722366333 test acc 0.40848214285714285
[epoch:29] loss 0.6851357420285543 acc 0.5807291666666666
[epoch:29] test loss 0.711510956287384 test acc 0.40625
[epoch:30] loss 0.6840842035081651 acc 0.5842013888888888
[epoch:30] test loss 0.7113214646066938 test acc 0.40848214285714285
[epoch:31] loss 0.6822013722525703 acc 0.6041666666666666
[epoch:31] test loss 0.7115010874611991 test acc 0.40848214285714285
Epoch 00033: reducing learning rate of group 0 to 5.1200e-05.
[epoch:32] loss 0.6788513527976142 acc 0.5842013888888888
[epoch:32] test loss 0.7124532546315875 test acc 0.40401785714285715
[epoch:33] loss 0.6778044634395175 acc 0.6041666666666666
[epoch:33] test loss 0.7126437085015433 test acc 0.40401785714285715
[epoch:34] loss 0.6754918628268771 acc 0.6024305555555556
[epoch:34] test loss 0.7128911018371582 test acc 0.40401785714285715
[epoch:35] loss 0.6757695012622409 acc 0.5894097222222222
[epoch:35] test loss 0.7146316851888385 test acc 0.3950892857142857
[epoch:36] loss 0.6756340397728814 acc 0.5954861111111112
[epoch:36] test loss 0.71221923828125 test acc 0.4107142857142857
[epoch:37] loss 0.6805736488766141 acc 0.5954861111111112
[epoch:37] test loss 0.7127971564020429 test acc 0.40848214285714285
[epoch:38] loss 0.6805587675836351 acc 0.5911458333333334
[epoch:38] test loss 0.7137306758335659 test acc 0.40401785714285715
[epoch:39] loss 0.6786513792143928 acc 0.5737847222222222
[epoch:39] test loss 0.7146177036421639 test acc 0.39955357142857145
Highest Test ACC : 0.4107142857142857
