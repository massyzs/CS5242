nohup: ignoring input
/home/xiao/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/xiao/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
  warn(f"Failed to load image Python extension: {e}")
/home/xiao/code/CS5242/CS5242/main.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  one_gt=torch.tensor(one_gt,dtype=torch.float32)
[epoch:0] loss 0.6856167167425156 acc 0.583984375
[epoch:0] test loss 0.7868518488747733 test acc 0.4029017857142857
[epoch:1] loss 0.7001327015459538 acc 0.59521484375
[epoch:1] test loss 0.8776501757758004 test acc 0.40513392857142855
[epoch:2] loss 0.7034629695117474 acc 0.58544921875
[epoch:2] test loss 0.8993834512574332 test acc 0.4017857142857143
[epoch:3] loss 0.698732502758503 acc 0.59326171875
[epoch:3] test loss 0.9075555716242109 test acc 0.4017857142857143
[epoch:4] loss 0.6944761611521244 acc 0.58642578125
[epoch:4] test loss 0.8886906674930027 test acc 0.40066964285714285
[epoch:5] loss 0.6930709779262543 acc 0.59814453125
[epoch:5] test loss 0.8354169981820243 test acc 0.40066964285714285
Epoch 00007: reducing learning rate of group 0 to 8.0000e-05.
[epoch:6] loss 0.6925166063010693 acc 0.59130859375
[epoch:6] test loss 0.8979635749544416 test acc 0.40625
[epoch:7] loss 0.6961430534720421 acc 0.58056640625
[epoch:7] test loss 0.895263842173985 test acc 0.40848214285714285
[epoch:8] loss 0.6883263476192951 acc 0.59716796875
[epoch:8] test loss 0.899054833820888 test acc 0.40401785714285715
[epoch:9] loss 0.6935812905430794 acc 0.59814453125
[epoch:9] test loss 0.897451034614018 test acc 0.40401785714285715
[epoch:10] loss 0.6928652375936508 acc 0.5927734375
[epoch:10] test loss 0.895052433013916 test acc 0.4029017857142857
[epoch:11] loss 0.6892242729663849 acc 0.60595703125
[epoch:11] test loss 0.8823139326913017 test acc 0.4029017857142857
Epoch 00013: reducing learning rate of group 0 to 6.4000e-05.
[epoch:12] loss 0.6879531256854534 acc 0.60205078125
[epoch:12] test loss 0.8242109247616359 test acc 0.3950892857142857
[epoch:13] loss 0.6737090349197388 acc 0.62109375
[epoch:13] test loss 0.7875338537352425 test acc 0.40848214285714285
[epoch:14] loss 0.6845126822590828 acc 0.6064453125
[epoch:14] test loss 0.7559310708727155 test acc 0.4140625
[epoch:15] loss 0.6688405685126781 acc 0.611328125
[epoch:15] test loss 0.6674801451819283 test acc 0.6216517857142857
[epoch:16] loss 0.6631274595856667 acc 0.62548828125
[epoch:16] test loss 0.6476345998900277 test acc 0.6071428571428571
[epoch:17] loss 0.6741845943033695 acc 0.60888671875
[epoch:17] test loss 0.6471611942563739 test acc 0.6372767857142857
[epoch:18] loss 0.6725568696856499 acc 0.62060546875
[epoch:18] test loss 0.6645647457667759 test acc 0.6495535714285714
[epoch:19] loss 0.6568799279630184 acc 0.63330078125
[epoch:19] test loss 0.6591083151953561 test acc 0.6116071428571429
[epoch:20] loss 0.6344049498438835 acc 0.66015625
[epoch:20] test loss 0.6426670125552586 test acc 0.6439732142857143
[epoch:21] loss 0.6327026225626469 acc 0.66015625
[epoch:21] test loss 0.6450727156230381 test acc 0.6428571428571429
[epoch:22] loss 0.6213226467370987 acc 0.67724609375
[epoch:22] test loss 0.6470032930374146 test acc 0.6372767857142857
[epoch:23] loss 0.6047143675386906 acc 0.6962890625
[epoch:23] test loss 0.6528198889323643 test acc 0.5915178571428571
[epoch:24] loss 0.6157579310238361 acc 0.6787109375
[epoch:24] test loss 0.6513747828347343 test acc 0.6205357142857143
[epoch:25] loss 0.6053170002996922 acc 0.6982421875
[epoch:25] test loss 0.6547765391213554 test acc 0.6261160714285714
[epoch:26] loss 0.5930531062185764 acc 0.7099609375
[epoch:26] test loss 0.6516584583691188 test acc 0.6026785714285714
[epoch:27] loss 0.5875372141599655 acc 0.71484375
[epoch:27] test loss 0.6567617229052952 test acc 0.6294642857142857
[epoch:28] loss 0.5898340381681919 acc 0.7197265625
[epoch:28] test loss 0.6578675338200161 test acc 0.6049107142857143
[epoch:29] loss 0.5896382741630077 acc 0.7177734375
[epoch:29] test loss 0.6656145623752049 test acc 0.6272321428571429
[epoch:30] loss 0.5846649743616581 acc 0.72314453125
[epoch:30] test loss 0.6512696743011475 test acc 0.6216517857142857
[epoch:31] loss 0.5862957611680031 acc 0.71728515625
[epoch:31] test loss 0.6556153638022286 test acc 0.6305803571428571
[epoch:32] loss 0.588641170412302 acc 0.71435546875
[epoch:32] test loss 0.651232395853315 test acc 0.6372767857142857
[epoch:33] loss 0.5745989978313446 acc 0.7294921875
[epoch:33] test loss 0.6548626337732587 test acc 0.6428571428571429
[epoch:34] loss 0.569865707308054 acc 0.74853515625
[epoch:34] test loss 0.6496512634413583 test acc 0.6540178571428571
[epoch:35] loss 0.570530004799366 acc 0.73193359375
[epoch:35] test loss 0.6582962359700885 test acc 0.6261160714285714
[epoch:36] loss 0.5668188314884901 acc 0.73779296875
[epoch:36] test loss 0.6717292751584735 test acc 0.6071428571428571
[epoch:37] loss 0.568413533270359 acc 0.744140625
[epoch:37] test loss 0.6579527344022479 test acc 0.6361607142857143
[epoch:38] loss 0.5725504793226719 acc 0.72802734375
[epoch:38] test loss 0.6819583773612976 test acc 0.5982142857142857
[epoch:39] loss 0.5699190013110638 acc 0.734375
[epoch:39] test loss 0.6637201309204102 test acc 0.6350446428571429
[epoch:40] loss 0.5571723207831383 acc 0.75634765625
[epoch:40] test loss 0.6655243975775582 test acc 0.6339285714285714
[epoch:41] loss 0.5613477304577827 acc 0.74658203125
[epoch:41] test loss 0.6873342224529811 test acc 0.5959821428571429
[epoch:42] loss 0.5668568126857281 acc 0.74560546875
[epoch:42] test loss 0.6643607190677098 test acc 0.6328125
[epoch:43] loss 0.5580869950354099 acc 0.75390625
[epoch:43] test loss 0.6690745779446193 test acc 0.625
[epoch:44] loss 0.55577571131289 acc 0.76318359375
[epoch:44] test loss 0.6726400596754891 test acc 0.6216517857142857
[epoch:45] loss 0.5538051873445511 acc 0.7587890625
[epoch:45] test loss 0.6701967971665519 test acc 0.6238839285714286
[epoch:46] loss 0.5394133422523737 acc 0.779296875
[epoch:46] test loss 0.6717698148318699 test acc 0.6261160714285714
[epoch:47] loss 0.5391776096075773 acc 0.77294921875
[epoch:47] test loss 0.6713286638259888 test acc 0.6205357142857143
[epoch:48] loss 0.5592643190175295 acc 0.75341796875
[epoch:48] test loss 0.6726458498409816 test acc 0.6183035714285714
[epoch:49] loss 0.5406633466482162 acc 0.77392578125
[epoch:49] test loss 0.680599970476968 test acc 0.6082589285714286
[epoch:50] loss 0.5443062800914049 acc 0.7646484375
[epoch:50] test loss 0.6851311581475394 test acc 0.6026785714285714
[epoch:51] loss 0.5396769717335701 acc 0.7744140625
[epoch:51] test loss 0.6933080724307469 test acc 0.5837053571428571
[epoch:52] loss 0.5548645108938217 acc 0.7568359375
[epoch:52] test loss 0.690920523234776 test acc 0.5959821428571429
Epoch 00054: reducing learning rate of group 0 to 5.1200e-05.
[epoch:53] loss 0.5432994775474072 acc 0.7724609375
[epoch:53] test loss 0.6876579608236041 test acc 0.59375
[epoch:54] loss 0.5336147528141737 acc 0.77490234375
[epoch:54] test loss 0.6724558302334377 test acc 0.6138392857142857
[epoch:55] loss 0.5425919368863106 acc 0.77734375
[epoch:55] test loss 0.6722352589879718 test acc 0.625
[epoch:56] loss 0.5421163383871317 acc 0.77783203125
[epoch:56] test loss 0.6687486001423427 test acc 0.6283482142857143
[epoch:57] loss 0.5443809237331152 acc 0.76806640625
[epoch:57] test loss 0.6645559923989433 test acc 0.6339285714285714
[epoch:58] loss 0.5383565984666348 acc 0.77685546875
[epoch:58] test loss 0.6691839609827314 test acc 0.6294642857142857
[epoch:59] loss 0.5430647432804108 acc 0.771484375
[epoch:59] test loss 0.6722003562109811 test acc 0.6283482142857143
Epoch 00061: reducing learning rate of group 0 to 4.0960e-05.
[epoch:60] loss 0.5377497170120478 acc 0.7802734375
[epoch:60] test loss 0.6710265874862671 test acc 0.6227678571428571
[epoch:61] loss 0.544848857447505 acc 0.76513671875
[epoch:61] test loss 0.6794038244656154 test acc 0.6183035714285714
[epoch:62] loss 0.5261391773819923 acc 0.7890625
[epoch:62] test loss 0.6953527331352234 test acc 0.5948660714285714
[epoch:63] loss 0.5325344577431679 acc 0.7890625
[epoch:63] test loss 0.68415881054742 test acc 0.6015625
[epoch:64] loss 0.5346050746738911 acc 0.779296875
[epoch:64] test loss 0.6739880016871861 test acc 0.6227678571428571
[epoch:65] loss 0.5311270635575056 acc 0.78125
[epoch:65] test loss 0.6922752686909267 test acc 0.5926339285714286
[epoch:66] loss 0.5173361953347921 acc 0.791015625
[epoch:66] test loss 0.6794585415295192 test acc 0.6171875
[epoch:67] loss 0.5310197528451681 acc 0.7841796875
[epoch:67] test loss 0.6807087148938861 test acc 0.6272321428571429
[epoch:68] loss 0.5351190268993378 acc 0.77685546875
[epoch:68] test loss 0.6808370522090367 test acc 0.6127232142857143
[epoch:69] loss 0.5368797183036804 acc 0.77001953125
[epoch:69] test loss 0.6998939599309649 test acc 0.5970982142857143
[epoch:70] loss 0.5273228213191032 acc 0.79052734375
[epoch:70] test loss 0.6897620814187186 test acc 0.5959821428571429
[epoch:71] loss 0.527465732768178 acc 0.78271484375
[epoch:71] test loss 0.688303359917232 test acc 0.5970982142857143
Epoch 00073: reducing learning rate of group 0 to 3.2768e-05.
[epoch:72] loss 0.5299401432275772 acc 0.77734375
[epoch:72] test loss 0.6837748885154724 test acc 0.5993303571428571
[epoch:73] loss 0.5305931214243174 acc 0.7841796875
[epoch:73] test loss 0.6968643495014736 test acc 0.5881696428571429
[epoch:74] loss 0.512678325176239 acc 0.79736328125
[epoch:74] test loss 0.6915824498449054 test acc 0.5915178571428571
[epoch:75] loss 0.5359080825001001 acc 0.775390625
[epoch:75] test loss 0.6840860162462506 test acc 0.6026785714285714
[epoch:76] loss 0.5212546773254871 acc 0.79248046875
[epoch:76] test loss 0.6983082379613604 test acc 0.5837053571428571
[epoch:77] loss 0.5304619371891022 acc 0.78515625
[epoch:77] test loss 0.6895830631256104 test acc 0.5970982142857143
[epoch:78] loss 0.5313334912061691 acc 0.7822265625
[epoch:78] test loss 0.6935550485338483 test acc 0.5859375
[epoch:79] loss 0.5228474605828524 acc 0.796875
[epoch:79] test loss 0.6998987538473946 test acc 0.5970982142857143
Epoch 00081: reducing learning rate of group 0 to 2.6214e-05.
[epoch:80] loss 0.5264456793665886 acc 0.78662109375
[epoch:80] test loss 0.6915280052593776 test acc 0.5926339285714286
[epoch:81] loss 0.5216318089514971 acc 0.79541015625
[epoch:81] test loss 0.6901531900678363 test acc 0.59375
[epoch:82] loss 0.5084912404417992 acc 0.8017578125
[epoch:82] test loss 0.6968500188418797 test acc 0.5870535714285714
[epoch:83] loss 0.5174744483083487 acc 0.80078125
[epoch:83] test loss 0.6931608659880502 test acc 0.5881696428571429
[epoch:84] loss 0.5224278271198273 acc 0.798828125
[epoch:84] test loss 0.691916857446943 test acc 0.5926339285714286
[epoch:85] loss 0.5223655719310045 acc 0.7939453125
[epoch:85] test loss 0.6942492297717503 test acc 0.5870535714285714
[epoch:86] loss 0.5079270768910646 acc 0.81103515625
[epoch:86] test loss 0.6942299945013863 test acc 0.5870535714285714
[epoch:87] loss 0.5131476242095232 acc 0.7998046875
[epoch:87] test loss 0.6910701990127563 test acc 0.5904017857142857
[epoch:88] loss 0.5105727296322584 acc 0.80517578125
[epoch:88] test loss 0.6927638564790998 test acc 0.5904017857142857
[epoch:89] loss 0.517210990190506 acc 0.78759765625
[epoch:89] test loss 0.6994252971240452 test acc 0.5881696428571429
[epoch:90] loss 0.5115532819181681 acc 0.80078125
[epoch:90] test loss 0.692065988268171 test acc 0.5915178571428571
[epoch:91] loss 0.5133997313678265 acc 0.80322265625
[epoch:91] test loss 0.7015266163008553 test acc 0.5848214285714286
Epoch 00093: reducing learning rate of group 0 to 2.0972e-05.
[epoch:92] loss 0.5146478712558746 acc 0.7978515625
[epoch:92] test loss 0.6965224317141941 test acc 0.5848214285714286
[epoch:93] loss 0.5180996954441071 acc 0.7978515625
[epoch:93] test loss 0.701944785458701 test acc 0.5892857142857143
[epoch:94] loss 0.5139094088226557 acc 0.8046875
[epoch:94] test loss 0.6963279502732413 test acc 0.5892857142857143
[epoch:95] loss 0.518280765041709 acc 0.7978515625
[epoch:95] test loss 0.6927977544920785 test acc 0.5915178571428571
[epoch:96] loss 0.5194752961397171 acc 0.79345703125
[epoch:96] test loss 0.6951075622013637 test acc 0.5881696428571429
[epoch:97] loss 0.5122898872941732 acc 0.80517578125
[epoch:97] test loss 0.7013994029590062 test acc 0.5892857142857143
[epoch:98] loss 0.5072875786572695 acc 0.80419921875
[epoch:98] test loss 0.69509300163814 test acc 0.5881696428571429
[epoch:99] loss 0.5146800149232149 acc 0.7998046875
[epoch:99] test loss 0.6927004541669574 test acc 0.5915178571428571
[epoch:100] loss 0.5158286336809397 acc 0.79931640625
[epoch:100] test loss 0.7029836262975421 test acc 0.5881696428571429
[epoch:101] loss 0.509841563180089 acc 0.80322265625
[epoch:101] test loss 0.7025568570409503 test acc 0.5837053571428571
[epoch:102] loss 0.5093891452997923 acc 0.806640625
[epoch:102] test loss 0.6998332994324821 test acc 0.5892857142857143
[epoch:103] loss 0.5084944553673267 acc 0.80517578125
[epoch:103] test loss 0.7048087971551078 test acc 0.5825892857142857
Epoch 00105: reducing learning rate of group 0 to 1.6777e-05.
[epoch:104] loss 0.516288373619318 acc 0.7939453125
[epoch:104] test loss 0.6953293510845729 test acc 0.5881696428571429
[epoch:105] loss 0.5045419950038195 acc 0.80712890625
[epoch:105] test loss 0.6979355045727321 test acc 0.5892857142857143
[epoch:106] loss 0.5061095673590899 acc 0.8095703125
[epoch:106] test loss 0.7000129052570888 test acc 0.5881696428571429
[epoch:107] loss 0.5060734357684851 acc 0.80859375
[epoch:107] test loss 0.6906149898256574 test acc 0.5982142857142857
[epoch:108] loss 0.509589746594429 acc 0.80810546875
[epoch:108] test loss 0.6976677009037563 test acc 0.5870535714285714
[epoch:109] loss 0.5106696616858244 acc 0.8046875
[epoch:109] test loss 0.700673588684627 test acc 0.5837053571428571
[epoch:110] loss 0.510128440335393 acc 0.80078125
[epoch:110] test loss 0.6997564775603158 test acc 0.5870535714285714
[epoch:111] loss 0.5034149698913097 acc 0.806640625
[epoch:111] test loss 0.6975985169410706 test acc 0.5825892857142857
[epoch:112] loss 0.49854253605008125 acc 0.8271484375
[epoch:112] test loss 0.697868117264339 test acc 0.5892857142857143
[epoch:113] loss 0.5150052271783352 acc 0.79833984375
[epoch:113] test loss 0.701551616191864 test acc 0.5848214285714286
[epoch:114] loss 0.5054304469376802 acc 0.80224609375
[epoch:114] test loss 0.6994489346231733 test acc 0.5881696428571429
[epoch:115] loss 0.5070941802114248 acc 0.8017578125
[epoch:115] test loss 0.696476766041347 test acc 0.5892857142857143
[epoch:116] loss 0.5069740992039442 acc 0.80517578125
[epoch:116] test loss 0.700039267539978 test acc 0.5892857142857143
[epoch:117] loss 0.5049760099500418 acc 0.806640625
[epoch:117] test loss 0.7037311792373657 test acc 0.5881696428571429
Epoch 00119: reducing learning rate of group 0 to 1.3422e-05.
[epoch:118] loss 0.5075664613395929 acc 0.80810546875
[epoch:118] test loss 0.6944373846054077 test acc 0.59375
[epoch:119] loss 0.505249435082078 acc 0.81201171875
[epoch:119] test loss 0.7004103830882481 test acc 0.5848214285714286
[epoch:120] loss 0.5098692700266838 acc 0.80322265625
[epoch:120] test loss 0.7004864301000323 test acc 0.5881696428571429
[epoch:121] loss 0.5096486248075962 acc 0.80615234375
[epoch:121] test loss 0.6969095894268581 test acc 0.5881696428571429
[epoch:122] loss 0.5069288294762373 acc 0.818359375
[epoch:122] test loss 0.7001075489180428 test acc 0.5881696428571429
[epoch:123] loss 0.5030343979597092 acc 0.80859375
[epoch:123] test loss 0.6967541830880302 test acc 0.5904017857142857
Epoch 00125: reducing learning rate of group 0 to 1.0737e-05.
[epoch:124] loss 0.5114739760756493 acc 0.80078125
[epoch:124] test loss 0.7030782529285976 test acc 0.5848214285714286
[epoch:125] loss 0.49860583059489727 acc 0.8095703125
[epoch:125] test loss 0.7004460436957223 test acc 0.5848214285714286
[epoch:126] loss 0.5013900473713875 acc 0.814453125
[epoch:126] test loss 0.6958435262952533 test acc 0.5892857142857143
[epoch:127] loss 0.5026469267904758 acc 0.81298828125
[epoch:127] test loss 0.7002652287483215 test acc 0.5870535714285714
[epoch:128] loss 0.5042863450944424 acc 0.81396484375
[epoch:128] test loss 0.6983146582330976 test acc 0.5892857142857143
[epoch:129] loss 0.5037839915603399 acc 0.8134765625
[epoch:129] test loss 0.7010128242628915 test acc 0.5848214285714286
Epoch 00131: reducing learning rate of group 0 to 8.5899e-06.
[epoch:130] loss 0.5023395530879498 acc 0.814453125
[epoch:130] test loss 0.6973267282758441 test acc 0.5881696428571429
[epoch:131] loss 0.5030896365642548 acc 0.80517578125
[epoch:131] test loss 0.7015592711312431 test acc 0.5881696428571429
[epoch:132] loss 0.5109709054231644 acc 0.7978515625
[epoch:132] test loss 0.7028111049107143 test acc 0.5825892857142857
[epoch:133] loss 0.494640588760376 acc 0.81884765625
[epoch:133] test loss 0.7007425001689366 test acc 0.5870535714285714
[epoch:134] loss 0.5041910484433174 acc 0.80859375
[epoch:134] test loss 0.6955809508051191 test acc 0.5892857142857143
[epoch:135] loss 0.4984523169696331 acc 0.8203125
[epoch:135] test loss 0.7059643268585205 test acc 0.5859375
[epoch:136] loss 0.5034702457487583 acc 0.80908203125
[epoch:136] test loss 0.6963396157537188 test acc 0.5892857142857143
[epoch:137] loss 0.5034650675952435 acc 0.80908203125
[epoch:137] test loss 0.7014012507029942 test acc 0.5837053571428571
[epoch:138] loss 0.502415394410491 acc 0.80517578125
[epoch:138] test loss 0.7009766527584621 test acc 0.5892857142857143
Epoch 00140: reducing learning rate of group 0 to 6.8719e-06.
[epoch:139] loss 0.4972129203379154 acc 0.8203125
[epoch:139] test loss 0.7025829553604126 test acc 0.5881696428571429
[epoch:140] loss 0.4990816209465265 acc 0.81640625
[epoch:140] test loss 0.6957752789769854 test acc 0.5892857142857143
[epoch:141] loss 0.4975712262094021 acc 0.8125
[epoch:141] test loss 0.702207795211247 test acc 0.5837053571428571
[epoch:142] loss 0.5138610750436783 acc 0.7978515625
[epoch:142] test loss 0.6932880282402039 test acc 0.59375
[epoch:143] loss 0.5009896736592054 acc 0.80908203125
[epoch:143] test loss 0.7016155549458095 test acc 0.5837053571428571
[epoch:144] loss 0.49824875965714455 acc 0.814453125
[epoch:144] test loss 0.698304295539856 test acc 0.5870535714285714
[epoch:145] loss 0.4941869229078293 acc 0.81982421875
[epoch:145] test loss 0.6922716242926461 test acc 0.59375
[epoch:146] loss 0.501348115503788 acc 0.81298828125
[epoch:146] test loss 0.6988166315214974 test acc 0.5892857142857143
[epoch:147] loss 0.505359223112464 acc 0.8134765625
[epoch:147] test loss 0.6992227264813015 test acc 0.5915178571428571
[epoch:148] loss 0.5000661723315716 acc 0.81494140625
[epoch:148] test loss 0.6998523133141654 test acc 0.5870535714285714
[epoch:149] loss 0.5048340409994125 acc 0.8046875
[epoch:149] test loss 0.6950247543198722 test acc 0.5959821428571429
[epoch:150] loss 0.5043251402676105 acc 0.81298828125
[epoch:150] test loss 0.6988996011870248 test acc 0.5948660714285714
Epoch 00152: reducing learning rate of group 0 to 5.4976e-06.
[epoch:151] loss 0.5058926045894623 acc 0.80517578125
[epoch:151] test loss 0.7007237332207816 test acc 0.5859375
[epoch:152] loss 0.4953104257583618 acc 0.82080078125
[epoch:152] test loss 0.7002504467964172 test acc 0.5881696428571429
[epoch:153] loss 0.49561177380383015 acc 0.81884765625
[epoch:153] test loss 0.6945156710488456 test acc 0.5915178571428571
[epoch:154] loss 0.4886360112577677 acc 0.82666015625
[epoch:154] test loss 0.6945849486759731 test acc 0.5915178571428571
[epoch:155] loss 0.5022686943411827 acc 0.8154296875
[epoch:155] test loss 0.6964268173490252 test acc 0.5881696428571429
[epoch:156] loss 0.499043095856905 acc 0.81298828125
[epoch:156] test loss 0.7021281634058271 test acc 0.5859375
[epoch:157] loss 0.50089923851192 acc 0.81494140625
[epoch:157] test loss 0.701336749962398 test acc 0.5859375
[epoch:158] loss 0.514842826873064 acc 0.7939453125
[epoch:158] test loss 0.7018404517854963 test acc 0.5915178571428571
[epoch:159] loss 0.5029757842421532 acc 0.80712890625
[epoch:159] test loss 0.70106588942664 test acc 0.5926339285714286
Epoch 00161: reducing learning rate of group 0 to 4.3980e-06.
[epoch:160] loss 0.5016213208436966 acc 0.8173828125
[epoch:160] test loss 0.6957964897155762 test acc 0.5948660714285714
[epoch:161] loss 0.5016006603837013 acc 0.81005859375
[epoch:161] test loss 0.7022195628711155 test acc 0.5881696428571429
[epoch:162] loss 0.5025078561156988 acc 0.80908203125
[epoch:162] test loss 0.7001887730189732 test acc 0.5915178571428571
[epoch:163] loss 0.5064931232482195 acc 0.798828125
[epoch:163] test loss 0.6996604204177856 test acc 0.5926339285714286
[epoch:164] loss 0.49955648370087147 acc 0.81689453125
[epoch:164] test loss 0.7000708324568612 test acc 0.5904017857142857
[epoch:165] loss 0.5036365650594234 acc 0.81005859375
[epoch:165] test loss 0.6947195359638759 test acc 0.5982142857142857
Epoch 00167: reducing learning rate of group 0 to 3.5184e-06.
[epoch:166] loss 0.500258719548583 acc 0.8095703125
[epoch:166] test loss 0.702310928276607 test acc 0.5904017857142857
[epoch:167] loss 0.4919909294694662 acc 0.826171875
[epoch:167] test loss 0.7042921526091439 test acc 0.5881696428571429
[epoch:168] loss 0.5067806150764227 acc 0.8056640625
[epoch:168] test loss 0.6988300681114197 test acc 0.5926339285714286
[epoch:169] loss 0.49737887643277645 acc 0.8203125
[epoch:169] test loss 0.6994754842349461 test acc 0.5904017857142857
[epoch:170] loss 0.5050122756510973 acc 0.80810546875
[epoch:170] test loss 0.6972740803446088 test acc 0.5915178571428571
[epoch:171] loss 0.5031831432133913 acc 0.81005859375
[epoch:171] test loss 0.6966638224465507 test acc 0.5948660714285714
Epoch 00173: reducing learning rate of group 0 to 2.8147e-06.
[epoch:172] loss 0.5048211719840765 acc 0.8076171875
[epoch:172] test loss 0.6995967285973685 test acc 0.59375
[epoch:173] loss 0.4916987959295511 acc 0.82373046875
[epoch:173] test loss 0.7006271140916007 test acc 0.5904017857142857
[epoch:174] loss 0.49903634935617447 acc 0.81298828125
[epoch:174] test loss 0.7036532504217965 test acc 0.5859375
[epoch:175] loss 0.5015777591615915 acc 0.8115234375
[epoch:175] test loss 0.6994131803512573 test acc 0.5904017857142857
[epoch:176] loss 0.49390747398138046 acc 0.822265625
[epoch:176] test loss 0.6963888321604047 test acc 0.5904017857142857
[epoch:177] loss 0.5004589632153511 acc 0.81103515625
[epoch:177] test loss 0.7009995239121574 test acc 0.5848214285714286
Epoch 00179: reducing learning rate of group 0 to 2.2518e-06.
[epoch:178] loss 0.49535842798650265 acc 0.82177734375
[epoch:178] test loss 0.6958562816892352 test acc 0.5915178571428571
[epoch:179] loss 0.5013453587889671 acc 0.810546875
[epoch:179] test loss 0.6957064270973206 test acc 0.5926339285714286
[epoch:180] loss 0.5069682244211435 acc 0.806640625
[epoch:180] test loss 0.6992007493972778 test acc 0.5915178571428571
[epoch:181] loss 0.4951312765479088 acc 0.818359375
[epoch:181] test loss 0.6978831972394671 test acc 0.5915178571428571
[epoch:182] loss 0.4958414565771818 acc 0.8134765625
[epoch:182] test loss 0.6979826433318002 test acc 0.5904017857142857
[epoch:183] loss 0.5091995187103748 acc 0.8095703125
[epoch:183] test loss 0.7009666647229876 test acc 0.5904017857142857
Epoch 00185: reducing learning rate of group 0 to 1.8014e-06.
[epoch:184] loss 0.513967027887702 acc 0.7958984375
[epoch:184] test loss 0.6981942823954991 test acc 0.5881696428571429
[epoch:185] loss 0.503168860450387 acc 0.814453125
[epoch:185] test loss 0.7034480997494289 test acc 0.5825892857142857
[epoch:186] loss 0.4963866416364908 acc 0.81298828125
[epoch:186] test loss 0.6971927029745919 test acc 0.5892857142857143
[epoch:187] loss 0.5014431513845921 acc 0.81201171875
[epoch:187] test loss 0.7021341664450509 test acc 0.5848214285714286
[epoch:188] loss 0.4985573850572109 acc 0.81591796875
[epoch:188] test loss 0.6988891107695443 test acc 0.5892857142857143
[epoch:189] loss 0.4968735985457897 acc 0.8193359375
[epoch:189] test loss 0.6984533582414899 test acc 0.5870535714285714
Epoch 00191: reducing learning rate of group 0 to 1.4412e-06.
[epoch:190] loss 0.4913513585925102 acc 0.83056640625
[epoch:190] test loss 0.6991918427603585 test acc 0.5881696428571429
[epoch:191] loss 0.49695361219346523 acc 0.81884765625
[epoch:191] test loss 0.7031339662415641 test acc 0.5825892857142857
[epoch:192] loss 0.494680842384696 acc 0.82080078125
[epoch:192] test loss 0.6992801598140171 test acc 0.5881696428571429
[epoch:193] loss 0.5026637520641088 acc 0.8095703125
[epoch:193] test loss 0.6986587813922337 test acc 0.5904017857142857
[epoch:194] loss 0.49105677753686905 acc 0.82177734375
[epoch:194] test loss 0.7047406605311802 test acc 0.5837053571428571
[epoch:195] loss 0.49844059348106384 acc 0.8125
[epoch:195] test loss 0.7031358480453491 test acc 0.5870535714285714
Epoch 00197: reducing learning rate of group 0 to 1.1529e-06.
[epoch:196] loss 0.5018962323665619 acc 0.80517578125
[epoch:196] test loss 0.7033799120358059 test acc 0.5859375
[epoch:197] loss 0.5055258478969336 acc 0.80224609375
[epoch:197] test loss 0.7014208350862775 test acc 0.5881696428571429
[epoch:198] loss 0.5030543319880962 acc 0.806640625
[epoch:198] test loss 0.6970994131905692 test acc 0.5915178571428571
[epoch:199] loss 0.4971247147768736 acc 0.8134765625
[epoch:199] test loss 0.7008360028266907 test acc 0.5904017857142857
