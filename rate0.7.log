nohup: ignoring input
/home/xiao/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/xiao/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
  warn(f"Failed to load image Python extension: {e}")
/home/xiao/code/CS5242/CS5242/main.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  one_gt=torch.tensor(one_gt,dtype=torch.float32)
[epoch:0] loss 0.6975373961031437 acc 0.5068359375
[epoch:0] test loss 0.6972395437104362 test acc 0.4017857142857143
[epoch:1] loss 0.6860782131552696 acc 0.5498046875
[epoch:1] test loss 0.702315662588392 test acc 0.39955357142857145
[epoch:2] loss 0.6840913891792297 acc 0.56787109375
[epoch:2] test loss 0.7046802384512765 test acc 0.40848214285714285
[epoch:3] loss 0.688024815171957 acc 0.5478515625
[epoch:3] test loss 0.7032063177653721 test acc 0.40513392857142855
[epoch:4] loss 0.679340060800314 acc 0.57080078125
[epoch:4] test loss 0.7054544006075177 test acc 0.39955357142857145
[epoch:5] loss 0.6697334125638008 acc 0.58935546875
[epoch:5] test loss 0.7105849214962551 test acc 0.40513392857142855
[epoch:6] loss 0.6678662449121475 acc 0.58349609375
[epoch:6] test loss 0.710929879120418 test acc 0.4017857142857143
[epoch:7] loss 0.6621242500841618 acc 0.60400390625
[epoch:7] test loss 0.7051417316709246 test acc 0.40513392857142855
[epoch:8] loss 0.663102500140667 acc 0.591796875
[epoch:8] test loss 0.7021458404404777 test acc 0.40513392857142855
[epoch:9] loss 0.6483978144824505 acc 0.60546875
[epoch:9] test loss 0.7008786627224514 test acc 0.41964285714285715
[epoch:10] loss 0.642840102314949 acc 0.62744140625
[epoch:10] test loss 0.701584552015577 test acc 0.43191964285714285
[epoch:11] loss 0.6445644795894623 acc 0.61474609375
[epoch:11] test loss 0.698385843208858 test acc 0.4486607142857143
[epoch:12] loss 0.6326934173703194 acc 0.63427734375
[epoch:12] test loss 0.6955330457006182 test acc 0.5133928571428571
[epoch:13] loss 0.6233389973640442 acc 0.6455078125
[epoch:13] test loss 0.6981690015111651 test acc 0.5100446428571429
[epoch:14] loss 0.6226506121456623 acc 0.6494140625
[epoch:14] test loss 0.6976545367922101 test acc 0.5167410714285714
[epoch:15] loss 0.6141503974795341 acc 0.65869140625
[epoch:15] test loss 0.6919543147087097 test acc 0.5703125
[epoch:16] loss 0.6188024878501892 acc 0.65625
[epoch:16] test loss 0.7003958310399737 test acc 0.5145089285714286
[epoch:17] loss 0.6014421842992306 acc 0.6826171875
[epoch:17] test loss 0.6911975485937936 test acc 0.5736607142857143
[epoch:18] loss 0.6030166037380695 acc 0.6845703125
[epoch:18] test loss 0.6933222753661019 test acc 0.5680803571428571
[epoch:19] loss 0.5969195328652859 acc 0.697265625
[epoch:19] test loss 0.6951210583959307 test acc 0.5546875
[epoch:20] loss 0.5959887802600861 acc 0.69482421875
[epoch:20] test loss 0.6872853636741638 test acc 0.59375
[epoch:21] loss 0.5854997336864471 acc 0.70947265625
[epoch:21] test loss 0.690624075276511 test acc 0.5848214285714286
[epoch:22] loss 0.5821983106434345 acc 0.7119140625
[epoch:22] test loss 0.6878508669989449 test acc 0.5982142857142857
[epoch:23] loss 0.5732554942369461 acc 0.7255859375
[epoch:23] test loss 0.6984516552516392 test acc 0.5680803571428571
[epoch:24] loss 0.5756818875670433 acc 0.7255859375
[epoch:24] test loss 0.6878783617700849 test acc 0.5881696428571429
[epoch:25] loss 0.5752467438578606 acc 0.7138671875
[epoch:25] test loss 0.6945162756102425 test acc 0.5591517857142857
[epoch:26] loss 0.5635591857135296 acc 0.74755859375
[epoch:26] test loss 0.6944927232606071 test acc 0.5602678571428571
[epoch:27] loss 0.564237367361784 acc 0.728515625
[epoch:27] test loss 0.6917564868927002 test acc 0.5859375
[epoch:28] loss 0.5533297508955002 acc 0.767578125
[epoch:28] test loss 0.7002049173627581 test acc 0.5334821428571429
[epoch:29] loss 0.5535080693662167 acc 0.7568359375
[epoch:29] test loss 0.6984145300728934 test acc 0.5412946428571429
[epoch:30] loss 0.5499289371073246 acc 0.75830078125
[epoch:30] test loss 0.6924322247505188 test acc 0.5703125
[epoch:31] loss 0.5442793443799019 acc 0.767578125
[epoch:31] test loss 0.7009952749524798 test acc 0.5279017857142857
[epoch:32] loss 0.545764246955514 acc 0.75390625
[epoch:32] test loss 0.6923196741512844 test acc 0.5825892857142857
[epoch:33] loss 0.5301656015217304 acc 0.78173828125
[epoch:33] test loss 0.6898042389324733 test acc 0.5513392857142857
[epoch:34] loss 0.5442667994648218 acc 0.76708984375
[epoch:34] test loss 0.725404577595847 test acc 0.5390625
[epoch:35] loss 0.5333143640309572 acc 0.77490234375
[epoch:35] test loss 0.6954432300158909 test acc 0.5747767857142857
[epoch:36] loss 0.5345786958932877 acc 0.775390625
[epoch:36] test loss 0.6991205811500549 test acc 0.5747767857142857
[epoch:37] loss 0.5365743972361088 acc 0.77734375
[epoch:37] test loss 0.7071414589881897 test acc 0.5524553571428571
[epoch:38] loss 0.5295315459370613 acc 0.7802734375
[epoch:38] test loss 0.7154560940606254 test acc 0.5234375
[epoch:39] loss 0.5328359231352806 acc 0.78173828125
[epoch:39] test loss 0.7054958684103829 test acc 0.53125
[epoch:40] loss 0.5287866313010454 acc 0.78125
[epoch:40] test loss 0.7123667853219169 test acc 0.5290178571428571
[epoch:41] loss 0.5276427995413542 acc 0.7919921875
[epoch:41] test loss 0.6993544272014073 test acc 0.5513392857142857
[epoch:42] loss 0.5170532166957855 acc 0.79248046875
[epoch:42] test loss 0.6981873171670097 test acc 0.5424107142857143
[epoch:43] loss 0.5145396627485752 acc 0.7998046875
[epoch:43] test loss 0.7162723115512303 test acc 0.5446428571428571
[epoch:44] loss 0.5154590476304293 acc 0.80078125
[epoch:44] test loss 0.7061946902956281 test acc 0.5256696428571429
[epoch:45] loss 0.5073300842195749 acc 0.80322265625
[epoch:45] test loss 0.7113161087036133 test acc 0.5401785714285714
[epoch:46] loss 0.5104811936616898 acc 0.8046875
[epoch:46] test loss 0.7196546452386039 test acc 0.5256696428571429
[epoch:47] loss 0.5178426615893841 acc 0.79052734375
[epoch:47] test loss 0.7093523229871478 test acc 0.5569196428571429
[epoch:48] loss 0.5060511529445648 acc 0.80908203125
[epoch:48] test loss 0.7366867320878165 test acc 0.5245535714285714
[epoch:49] loss 0.5176207348704338 acc 0.794921875
[epoch:49] test loss 0.7227957929883685 test acc 0.53125
[epoch:50] loss 0.5089145805686712 acc 0.80517578125
[epoch:50] test loss 0.7090672765459333 test acc 0.5446428571428571
[epoch:51] loss 0.5068385414779186 acc 0.8017578125
[epoch:51] test loss 0.7105872716222491 test acc 0.5502232142857143
[epoch:52] loss 0.5078121293336153 acc 0.80029296875
[epoch:52] test loss 0.7119799511773246 test acc 0.5602678571428571
[epoch:53] loss 0.502744622528553 acc 0.810546875
[epoch:53] test loss 0.7249564102717808 test acc 0.5078125
[epoch:54] loss 0.5060740578919649 acc 0.80908203125
[epoch:54] test loss 0.7168811900275094 test acc 0.5390625
[epoch:55] loss 0.5012159943580627 acc 0.8125
[epoch:55] test loss 0.7179223724773952 test acc 0.5580357142857143
[epoch:56] loss 0.5007171146571636 acc 0.8115234375
[epoch:56] test loss 0.7261960421289716 test acc 0.5212053571428571
[epoch:57] loss 0.4992018807679415 acc 0.80859375
[epoch:57] test loss 0.709648140839168 test acc 0.5334821428571429
[epoch:58] loss 0.49097446724772453 acc 0.8271484375
[epoch:58] test loss 0.7378893068858555 test acc 0.5066964285714286
[epoch:59] loss 0.4951300360262394 acc 0.81982421875
[epoch:59] test loss 0.7213954755238124 test acc 0.5345982142857143
[epoch:60] loss 0.49280369840562344 acc 0.81787109375
[epoch:60] test loss 0.7267057555062431 test acc 0.5424107142857143
[epoch:61] loss 0.49014983884990215 acc 0.8271484375
[epoch:61] test loss 0.7404892018863133 test acc 0.49107142857142855
[epoch:62] loss 0.49124512635171413 acc 0.82373046875
[epoch:62] test loss 0.7475697568484715 test acc 0.48325892857142855
[epoch:63] loss 0.49352416582405567 acc 0.8203125
[epoch:63] test loss 0.7412924681391034 test acc 0.515625
[epoch:64] loss 0.4900672510266304 acc 0.81689453125
[epoch:64] test loss 0.7248816064425877 test acc 0.5066964285714286
[epoch:65] loss 0.4910268262028694 acc 0.818359375
[epoch:65] test loss 0.7357213071414402 test acc 0.5055803571428571
[epoch:66] loss 0.48840024322271347 acc 0.8193359375
[epoch:66] test loss 0.7587235059056964 test acc 0.5078125
[epoch:67] loss 0.4860288091003895 acc 0.82666015625
[epoch:67] test loss 0.7356994066919599 test acc 0.5055803571428571
[epoch:68] loss 0.48315014131367207 acc 0.82861328125
[epoch:68] test loss 0.7480260900088719 test acc 0.48549107142857145
[epoch:69] loss 0.4926222115755081 acc 0.81591796875
[epoch:69] test loss 0.7458521042551313 test acc 0.5022321428571429
[epoch:70] loss 0.4865484591573477 acc 0.83154296875
[epoch:70] test loss 0.7322946531432015 test acc 0.49441964285714285
[epoch:71] loss 0.4854109324514866 acc 0.82958984375
[epoch:71] test loss 0.7494911551475525 test acc 0.46986607142857145
[epoch:72] loss 0.48285173811018467 acc 0.8310546875
[epoch:72] test loss 0.7524312734603882 test acc 0.48214285714285715
[epoch:73] loss 0.4847292900085449 acc 0.83251953125
[epoch:73] test loss 0.750762939453125 test acc 0.5078125
[epoch:74] loss 0.47683971747756004 acc 0.83935546875
[epoch:74] test loss 0.7511319858687264 test acc 0.5066964285714286
[epoch:75] loss 0.48392259143292904 acc 0.8251953125
[epoch:75] test loss 0.7623634423528399 test acc 0.48995535714285715
[epoch:76] loss 0.4777672104537487 acc 0.8408203125
[epoch:76] test loss 0.7681721193449838 test acc 0.46205357142857145
[epoch:77] loss 0.47760983370244503 acc 0.8388671875
[epoch:77] test loss 0.7524900351251874 test acc 0.48325892857142855
[epoch:78] loss 0.4783252440392971 acc 0.83447265625
[epoch:78] test loss 0.7566380075045994 test acc 0.46986607142857145
[epoch:79] loss 0.48189679719507694 acc 0.83154296875
[epoch:79] test loss 0.7530007362365723 test acc 0.4877232142857143
Epoch 00081: reducing learning rate of group 0 to 8.0000e-05.
[epoch:80] loss 0.4782410115003586 acc 0.830078125
[epoch:80] test loss 0.72908102614539 test acc 0.5223214285714286
[epoch:81] loss 0.4763811305165291 acc 0.83642578125
[epoch:81] test loss 0.7652367353439331 test acc 0.5
[epoch:82] loss 0.4685043767094612 acc 0.845703125
[epoch:82] test loss 0.7677376014845712 test acc 0.45982142857142855
[epoch:83] loss 0.46872762218117714 acc 0.84619140625
[epoch:83] test loss 0.7718042646135602 test acc 0.4921875
[epoch:84] loss 0.46848068200051785 acc 0.84423828125
[epoch:84] test loss 0.7640424370765686 test acc 0.4575892857142857
[epoch:85] loss 0.46363426744937897 acc 0.85546875
[epoch:85] test loss 0.7629921862057277 test acc 0.4720982142857143
[epoch:86] loss 0.46949425898492336 acc 0.8515625
[epoch:86] test loss 0.7710157547678266 test acc 0.48325892857142855
[epoch:87] loss 0.4670439939945936 acc 0.84521484375
[epoch:87] test loss 0.764872567994254 test acc 0.4877232142857143
[epoch:88] loss 0.46190176345407963 acc 0.853515625
[epoch:88] test loss 0.7714199423789978 test acc 0.4921875
[epoch:89] loss 0.4676581025123596 acc 0.8515625
[epoch:89] test loss 0.7682766233171735 test acc 0.4720982142857143
[epoch:90] loss 0.46376052871346474 acc 0.85009765625
[epoch:90] test loss 0.7672186068126133 test acc 0.49441964285714285
[epoch:91] loss 0.4631982874125242 acc 0.85302734375
[epoch:91] test loss 0.7701705523899623 test acc 0.48995535714285715
[epoch:92] loss 0.4681073073297739 acc 0.84521484375
[epoch:92] test loss 0.773428201675415 test acc 0.46875
[epoch:93] loss 0.4653652608394623 acc 0.84814453125
[epoch:93] test loss 0.761493274143764 test acc 0.515625
Epoch 00095: reducing learning rate of group 0 to 6.4000e-05.
[epoch:94] loss 0.4650710802525282 acc 0.85107421875
[epoch:94] test loss 0.7602456637791225 test acc 0.49107142857142855
[epoch:95] loss 0.4612904563546181 acc 0.85546875
[epoch:95] test loss 0.7695739269256592 test acc 0.48325892857142855
[epoch:96] loss 0.46554602868855 acc 0.85009765625
[epoch:96] test loss 0.7796840667724609 test acc 0.48214285714285715
[epoch:97] loss 0.4553366247564554 acc 0.86083984375
[epoch:97] test loss 0.7710562348365784 test acc 0.4877232142857143
[epoch:98] loss 0.45725072734057903 acc 0.8564453125
[epoch:98] test loss 0.7739895752498082 test acc 0.48325892857142855
[epoch:99] loss 0.4574335590004921 acc 0.85595703125
[epoch:99] test loss 0.7821362359183175 test acc 0.47544642857142855
[epoch:100] loss 0.4599801320582628 acc 0.85986328125
[epoch:100] test loss 0.7671065756252834 test acc 0.4765625
[epoch:101] loss 0.4634775184094906 acc 0.849609375
[epoch:101] test loss 0.7663973229272025 test acc 0.4810267857142857
[epoch:102] loss 0.45157515630126 acc 0.86474609375
[epoch:102] test loss 0.7722569278308323 test acc 0.4877232142857143
[epoch:103] loss 0.45944247767329216 acc 0.85205078125
[epoch:103] test loss 0.7768857138497489 test acc 0.4921875
[epoch:104] loss 0.4554619826376438 acc 0.85595703125
[epoch:104] test loss 0.7634651575769696 test acc 0.49107142857142855
[epoch:105] loss 0.4527929723262787 acc 0.8623046875
[epoch:105] test loss 0.7765930720738002 test acc 0.49107142857142855
[epoch:106] loss 0.4553820863366127 acc 0.86083984375
[epoch:106] test loss 0.7857920527458191 test acc 0.4497767857142857
[epoch:107] loss 0.4539295695722103 acc 0.8603515625
[epoch:107] test loss 0.7832714148930141 test acc 0.4720982142857143
Epoch 00109: reducing learning rate of group 0 to 5.1200e-05.
[epoch:108] loss 0.4571960996836424 acc 0.85302734375
[epoch:108] test loss 0.775118316922869 test acc 0.48325892857142855
[epoch:109] loss 0.4535493068397045 acc 0.8623046875
[epoch:109] test loss 0.7853675058909825 test acc 0.45982142857142855
[epoch:110] loss 0.45794925279915333 acc 0.85986328125
[epoch:110] test loss 0.7768946119717189 test acc 0.4642857142857143
[epoch:111] loss 0.4475249759852886 acc 0.86767578125
[epoch:111] test loss 0.7729339344160897 test acc 0.4765625
[epoch:112] loss 0.4473004825413227 acc 0.8662109375
[epoch:112] test loss 0.7784151945795331 test acc 0.484375
[epoch:113] loss 0.45151931792497635 acc 0.861328125
[epoch:113] test loss 0.7811453172138759 test acc 0.45982142857142855
[epoch:114] loss 0.45545758679509163 acc 0.86376953125
[epoch:114] test loss 0.7892239093780518 test acc 0.453125
[epoch:115] loss 0.45077809877693653 acc 0.86474609375
[epoch:115] test loss 0.7781876410756793 test acc 0.47544642857142855
[epoch:116] loss 0.4511216338723898 acc 0.8623046875
[epoch:116] test loss 0.7807820439338684 test acc 0.48325892857142855
[epoch:117] loss 0.4411809965968132 acc 0.87451171875
[epoch:117] test loss 0.7834209459168571 test acc 0.4732142857142857
[epoch:118] loss 0.44769561663269997 acc 0.8662109375
[epoch:118] test loss 0.7781912854739598 test acc 0.4765625
[epoch:119] loss 0.45397400110960007 acc 0.85693359375
[epoch:119] test loss 0.7797192590577262 test acc 0.4732142857142857
[epoch:120] loss 0.4504150990396738 acc 0.86474609375
[epoch:120] test loss 0.7769608582769122 test acc 0.47879464285714285
[epoch:121] loss 0.44761642441153526 acc 0.8681640625
[epoch:121] test loss 0.7801246047019958 test acc 0.47544642857142855
[epoch:122] loss 0.4437964875251055 acc 0.87353515625
[epoch:122] test loss 0.7837698800223214 test acc 0.48325892857142855
Epoch 00124: reducing learning rate of group 0 to 4.0960e-05.
[epoch:123] loss 0.44179780408740044 acc 0.87646484375
[epoch:123] test loss 0.777465215751103 test acc 0.48214285714285715
[epoch:124] loss 0.44978056475520134 acc 0.8662109375
[epoch:124] test loss 0.7807479756219047 test acc 0.47767857142857145
[epoch:125] loss 0.44602533616125584 acc 0.87109375
[epoch:125] test loss 0.7837736521448407 test acc 0.46986607142857145
[epoch:126] loss 0.44755773060023785 acc 0.8681640625
[epoch:126] test loss 0.7803139175687518 test acc 0.47879464285714285
[epoch:127] loss 0.4514489658176899 acc 0.86474609375
[epoch:127] test loss 0.7876189180782863 test acc 0.4720982142857143
[epoch:128] loss 0.44664762541651726 acc 0.86865234375
[epoch:128] test loss 0.7786936504500253 test acc 0.47767857142857145
[epoch:129] loss 0.43912437185645103 acc 0.88134765625
[epoch:129] test loss 0.7904518842697144 test acc 0.4609375
[epoch:130] loss 0.4483860991895199 acc 0.8662109375
[epoch:130] test loss 0.7875226650919233 test acc 0.453125
[epoch:131] loss 0.44337003864347935 acc 0.8701171875
[epoch:131] test loss 0.7885769009590149 test acc 0.45982142857142855
[epoch:132] loss 0.4456876628100872 acc 0.8701171875
[epoch:132] test loss 0.790670497076852 test acc 0.4575892857142857
[epoch:133] loss 0.4400082118809223 acc 0.87451171875
[epoch:133] test loss 0.7897583586829049 test acc 0.4642857142857143
[epoch:134] loss 0.44294438883662224 acc 0.869140625
[epoch:134] test loss 0.7860571571758815 test acc 0.46651785714285715
Epoch 00136: reducing learning rate of group 0 to 3.2768e-05.
[epoch:135] loss 0.44169314578175545 acc 0.873046875
[epoch:135] test loss 0.7760466933250427 test acc 0.48995535714285715
[epoch:136] loss 0.4401415213942528 acc 0.87646484375
[epoch:136] test loss 0.7961629373686654 test acc 0.46875
[epoch:137] loss 0.4435798153281212 acc 0.87353515625
[epoch:137] test loss 0.7804801208632333 test acc 0.4642857142857143
[epoch:138] loss 0.44167405739426613 acc 0.880859375
[epoch:138] test loss 0.7839468887874058 test acc 0.46651785714285715
[epoch:139] loss 0.435640187934041 acc 0.88623046875
[epoch:139] test loss 0.7969687070165362 test acc 0.47767857142857145
[epoch:140] loss 0.44492692686617374 acc 0.87109375
[epoch:140] test loss 0.7912272810935974 test acc 0.46205357142857145
[epoch:141] loss 0.43889102526009083 acc 0.8759765625
[epoch:141] test loss 0.7956506269318717 test acc 0.4419642857142857
[epoch:142] loss 0.4412069823592901 acc 0.87353515625
[epoch:142] test loss 0.7975124035562787 test acc 0.4564732142857143
[epoch:143] loss 0.4366285093128681 acc 0.8779296875
[epoch:143] test loss 0.7902382782527378 test acc 0.4642857142857143
[epoch:144] loss 0.4429045785218477 acc 0.87060546875
[epoch:144] test loss 0.7906909670148577 test acc 0.4609375
Epoch 00146: reducing learning rate of group 0 to 2.6214e-05.
[epoch:145] loss 0.43679434433579445 acc 0.8759765625
[epoch:145] test loss 0.7944351945604596 test acc 0.4654017857142857
[epoch:146] loss 0.43253168277442455 acc 0.88232421875
[epoch:146] test loss 0.7839448026248387 test acc 0.4654017857142857
[epoch:147] loss 0.43390551395714283 acc 0.884765625
[epoch:147] test loss 0.785261903490339 test acc 0.4642857142857143
[epoch:148] loss 0.43467878736555576 acc 0.8798828125
[epoch:148] test loss 0.7924766881125314 test acc 0.45982142857142855
[epoch:149] loss 0.4341089818626642 acc 0.8818359375
[epoch:149] test loss 0.7865900482450213 test acc 0.45424107142857145
[epoch:150] loss 0.4400231223553419 acc 0.87646484375
[epoch:150] test loss 0.7986667326518467 test acc 0.4486607142857143
[epoch:151] loss 0.43531211093068123 acc 0.87939453125
[epoch:151] test loss 0.7955796122550964 test acc 0.45535714285714285
[epoch:152] loss 0.4311268851161003 acc 0.88916015625
[epoch:152] test loss 0.7992522120475769 test acc 0.453125
[epoch:153] loss 0.4359300546348095 acc 0.880859375
[epoch:153] test loss 0.794560262135097 test acc 0.44642857142857145
[epoch:154] loss 0.43612186796963215 acc 0.88330078125
[epoch:154] test loss 0.7929216793605259 test acc 0.453125
[epoch:155] loss 0.4369146190583706 acc 0.87158203125
[epoch:155] test loss 0.7958435927118573 test acc 0.4497767857142857
[epoch:156] loss 0.4361732415854931 acc 0.880859375
[epoch:156] test loss 0.796452922480447 test acc 0.4497767857142857
[epoch:157] loss 0.44167172349989414 acc 0.87158203125
[epoch:157] test loss 0.7969762768064227 test acc 0.4486607142857143
Epoch 00159: reducing learning rate of group 0 to 2.0972e-05.
[epoch:158] loss 0.4385208375751972 acc 0.8740234375
[epoch:158] test loss 0.7931418589183262 test acc 0.44642857142857145
[epoch:159] loss 0.4353316407650709 acc 0.87890625
[epoch:159] test loss 0.8006974969591413 test acc 0.45424107142857145
[epoch:160] loss 0.4365334715694189 acc 0.880859375
[epoch:160] test loss 0.7988854816981724 test acc 0.4720982142857143
[epoch:161] loss 0.43794012255966663 acc 0.87939453125
[epoch:161] test loss 0.8042128682136536 test acc 0.4497767857142857
[epoch:162] loss 0.43429054133594036 acc 0.87890625
[epoch:162] test loss 0.7987643224852425 test acc 0.43638392857142855
[epoch:163] loss 0.43055391125380993 acc 0.8876953125
[epoch:163] test loss 0.7979141814368111 test acc 0.44308035714285715
[epoch:164] loss 0.43657088093459606 acc 0.87890625
[epoch:164] test loss 0.7991528596196856 test acc 0.44308035714285715
[epoch:165] loss 0.4385742712765932 acc 0.87646484375
[epoch:165] test loss 0.7955811704908099 test acc 0.43973214285714285
[epoch:166] loss 0.4389256704598665 acc 0.87841796875
[epoch:166] test loss 0.7941732491765704 test acc 0.44642857142857145
[epoch:167] loss 0.43188262544572353 acc 0.88427734375
[epoch:167] test loss 0.8055169837815421 test acc 0.4408482142857143
[epoch:168] loss 0.43276325799524784 acc 0.88671875
[epoch:168] test loss 0.7953324232782636 test acc 0.4497767857142857
Epoch 00170: reducing learning rate of group 0 to 1.6777e-05.
[epoch:169] loss 0.43507056310772896 acc 0.87646484375
[epoch:169] test loss 0.7990212866238185 test acc 0.44419642857142855
[epoch:170] loss 0.43239697255194187 acc 0.8857421875
[epoch:170] test loss 0.7988368953977313 test acc 0.45089285714285715
[epoch:171] loss 0.43214376643300056 acc 0.884765625
[epoch:171] test loss 0.8010789666857038 test acc 0.45200892857142855
[epoch:172] loss 0.4326330032199621 acc 0.884765625
[epoch:172] test loss 0.7983418617929731 test acc 0.45200892857142855
[epoch:173] loss 0.4359986465424299 acc 0.87841796875
[epoch:173] test loss 0.7982806137629918 test acc 0.45089285714285715
[epoch:174] loss 0.43529742024838924 acc 0.88037109375
[epoch:174] test loss 0.8015475443431309 test acc 0.44754464285714285
[epoch:175] loss 0.42967264726758003 acc 0.8876953125
[epoch:175] test loss 0.8028192094394139 test acc 0.4564732142857143
[epoch:176] loss 0.43423558957874775 acc 0.87841796875
[epoch:176] test loss 0.8025404044560024 test acc 0.44754464285714285
[epoch:177] loss 0.4281690176576376 acc 0.888671875
[epoch:177] test loss 0.8012778844152179 test acc 0.4419642857142857
[epoch:178] loss 0.4322387930005789 acc 0.88671875
[epoch:178] test loss 0.8043409671102252 test acc 0.4453125
[epoch:179] loss 0.4298207014799118 acc 0.88232421875
[epoch:179] test loss 0.8044949429375785 test acc 0.4486607142857143
[epoch:180] loss 0.43673935160040855 acc 0.87744140625
[epoch:180] test loss 0.8010610938072205 test acc 0.44754464285714285
[epoch:181] loss 0.42901953123509884 acc 0.89111328125
[epoch:181] test loss 0.795917170388358 test acc 0.45089285714285715
[epoch:182] loss 0.42979975044727325 acc 0.88525390625
[epoch:182] test loss 0.800304114818573 test acc 0.44642857142857145
Epoch 00184: reducing learning rate of group 0 to 1.3422e-05.
[epoch:183] loss 0.4310202691704035 acc 0.88916015625
[epoch:183] test loss 0.8001573256083897 test acc 0.45200892857142855
[epoch:184] loss 0.4281767811626196 acc 0.88916015625
[epoch:184] test loss 0.7937307783535549 test acc 0.4497767857142857
[epoch:185] loss 0.43118893913924694 acc 0.8837890625
[epoch:185] test loss 0.8044241496494838 test acc 0.44308035714285715
[epoch:186] loss 0.4368563760071993 acc 0.88232421875
[epoch:186] test loss 0.8029082587787083 test acc 0.4453125
[epoch:187] loss 0.4316409230232239 acc 0.8876953125
[epoch:187] test loss 0.801963882786887 test acc 0.43973214285714285
[epoch:188] loss 0.43108332715928555 acc 0.88330078125
[epoch:188] test loss 0.8007547174181256 test acc 0.44419642857142855
[epoch:189] loss 0.4267332851886749 acc 0.88623046875
[epoch:189] test loss 0.8055151956421989 test acc 0.4486607142857143
[epoch:190] loss 0.43094094283878803 acc 0.88818359375
[epoch:190] test loss 0.8019647342818124 test acc 0.4453125
[epoch:191] loss 0.43655144423246384 acc 0.8818359375
[epoch:191] test loss 0.8079964688846043 test acc 0.43526785714285715
[epoch:192] loss 0.43050139024853706 acc 0.884765625
[epoch:192] test loss 0.8016062123434884 test acc 0.4497767857142857
[epoch:193] loss 0.4288361370563507 acc 0.8896484375
[epoch:193] test loss 0.8012186459132603 test acc 0.44308035714285715
[epoch:194] loss 0.4365744050592184 acc 0.87939453125
[epoch:194] test loss 0.8029475382396153 test acc 0.4408482142857143
Epoch 00196: reducing learning rate of group 0 to 1.0737e-05.
[epoch:195] loss 0.42723067104816437 acc 0.892578125
[epoch:195] test loss 0.8071060180664062 test acc 0.43638392857142855
[epoch:196] loss 0.42531051114201546 acc 0.89111328125
[epoch:196] test loss 0.8069138697215489 test acc 0.43861607142857145
[epoch:197] loss 0.4328693300485611 acc 0.880859375
[epoch:197] test loss 0.8075619169643947 test acc 0.43861607142857145
[epoch:198] loss 0.4186027552932501 acc 0.89892578125
[epoch:198] test loss 0.7979688559259687 test acc 0.4486607142857143
[epoch:199] loss 0.4300300367176533 acc 0.88671875
[epoch:199] test loss 0.8000361408506121 test acc 0.44419642857142855
